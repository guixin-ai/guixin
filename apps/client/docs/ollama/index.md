# Ollama 本地模型管理

Ollama 是一款强大的本地大语言模型管理工具，硅信通过与 Ollama 深度集成，让您能够在本地运行各种开源大语言模型。这不仅保护了您的隐私（所有数据都在本地处理），还能在无网络环境下使用 AI 功能。

## Ollama 的主要优势

- **完全本地化**：所有处理都在您的设备上进行，数据不会离开您的电脑
- **离线工作**：无需网络连接也能使用 AI 功能
- **多种模型支持**：支持多种主流开源大语言模型
- **自由定制**：可根据需求自定义和调整模型参数
- **保护隐私**：敏感数据不会传输到外部服务器

## 在硅信中使用 Ollama

硅信应用提供了全面的 Ollama 管理功能，让您能够轻松地：

1. **安装和配置** Ollama 服务
2. **下载和管理** 各种大语言模型
3. **优化性能** 以适应不同的硬件环境
4. **排查问题** 并解决常见故障

## 快速入门

要开始使用 Ollama 本地模型，请按照以下步骤操作：

1. [安装和配置 Ollama](/ollama/setup) - 设置 Ollama 环境
2. [下载模型](/ollama/download) - 获取适合您需求的语言模型
3. [管理模型](/ollama/manage) - 查看、使用和删除已安装模型
4. [性能优化](/ollama/performance) - 根据您的硬件调整设置

## 推荐模型

硅信推荐以下几种在本地运行效果良好的模型：

| 模型    | 特点                   | 适用场景           | 资源要求 |
| ------- | ---------------------- | ------------------ | -------- |
| Llama 2 | Meta 开发的通用模型    | 一般对话、知识问答 | 中等     |
| Mistral | 高效开源模型           | 指令遵循、效率优先 | 较低     |
| Qwen    | 阿里开发的中文优化模型 | 中文对话、内容创作 | 中等     |
| Gemma   | Google 开发的轻量模型  | 资源受限设备       | 较低     |

## 常见问题

如果您在使用过程中遇到问题，可以查看我们的[常见问题](/ollama/faq)页面，或浏览以下快速解答：

- **Ollama 无法连接** - 确保 Ollama 已正确安装并运行
- **模型下载失败** - 检查网络连接和存储空间
- **模型响应缓慢** - 尝试使用更小的模型或调整性能参数

## 下一步

立即前往[安装配置](/ollama/setup)页面，开始您的本地 AI 之旅！
