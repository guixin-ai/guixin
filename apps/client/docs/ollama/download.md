# 下载模型

在安装配置 Ollama 后，您需要下载模型才能开始使用。本指南将帮助您了解如何下载模型、选择适合的模型以及解决常见下载问题。

> **重要提示**：只有当 Ollama 服务状态显示为"在线"时，您才能使用下载功能并查看已安装的模型列表。如果服务状态为"离线"，请确保 Ollama 服务已正确启动。

## 下载步骤

1. 在硅信中进入"设置" > "Ollama 本地模型管理"
2. 确认 Ollama 服务状态为"在线"（页面顶部绿色标志）
3. 点击"访问模型库"链接查看可用模型（或直接访问 [Ollama 官方模型库](https://ollama.ai/library)）
4. 从模型库复制模型命令（如 `ollama run llama3`）并粘贴到输入框，系统会自动提取模型名称
5. 或者直接在输入框中输入要下载的模型名称（格式见下文）
6. 点击"下载"按钮开始下载
7. 下载进度会实时显示在界面上
8. 下载完成后，模型会自动出现在已安装模型列表中

## 模型下载队列

Ollama 一次只能下载一个模型，但硅信提供了模型下载队列功能：

1. 您可以连续添加多个模型到下载队列
2. 界面将显示当前正在下载的模型和等待下载的模型列表
3. 当一个模型下载完成后，系统会自动开始下载队列中的下一个模型
4. 下载完成的模型会自动出现在已安装模型列表中

> **注意**：受 Ollama API 限制，一次只能下载一个模型，其他模型将在队列中等待。

## 应用关闭时的下载行为

当您在模型下载过程中关闭硅信应用时，系统会有以下行为：

1. **当前下载继续进行**：由于 Ollama 服务是独立运行的，当前正在下载的模型会在 Ollama 服务中继续下载，不会中断
2. **队列中的模型不会继续处理**：虽然当前模型会继续下载，但队列中等待的其他模型将不会自动开始下载
3. **下载状态不再更新**：由于应用已关闭，您将无法看到下载进度
4. **应用再次打开时恢复下载**：当您重新打开应用时，系统会自动恢复之前的下载，并续接已经完成的进度
5. **验证下载完成情况**：应用会检查之前正在下载的模型是否已完成，并更新队列状态

因此，为了确保所有排队的模型都能顺利下载，建议在下载队列处理完毕之前不要关闭应用。如果必须关闭应用，请在重新打开后检查下载状态并根据需要重新开始未完成的下载。

## 刷新页面时的下载行为

如果您在模型下载过程中刷新页面：

1. **下载自动续接**：系统会自动检测到之前的下载状态，并继续下载，无需重新开始
2. **进度保留**：由于 Ollama 服务在后台持续运行，之前已下载的部分不会丢失
3. **队列恢复**：下载队列状态会被恢复，包括等待中和失败的下载项

## 下载失败处理

当模型下载过程中遇到问题时，系统会按以下方式处理：

1. **立即标记失败**：如果下载过程中出现异常，系统会立即将该下载任务标记为失败
2. **显示错误原因**：下载失败的项目会显示具体的错误原因，帮助您了解失败的具体情况
3. **队列继续处理**：如果某个模型下载失败，系统会继续处理队列中的下一个模型
4. **断点续传**：当您点击失败项旁边的"重试"按钮时，系统会从之前的断点处继续下载，不会重新下载全部内容
5. **批量重试**：当队列中所有模型都处理完毕后，您可以选择重试所有失败的模型，同样会从之前的断点处续传

由于网络问题、服务器限制或其他原因，某些下载可能会失败。当发生失败时，您需要手动点击"重试"来继续下载。

## 模型名称格式

Ollama 模型名称通常遵循以下格式：

```
模型名称:标签
```

例如：`llama3:8b-instruct-q4_0`

其中：

- **模型名称**：基础模型的名称，如 llama3、qwen、yi 等
- **标签**：可选，通常包含模型尺寸和量化信息

常见标签说明：

- **参数量标记**：例如 8b、14b、70b 等，表示模型的参数量大小
- **用途标记**：
  - `instruct` - 优化过的指令调整版本
  - `chat` - 针对对话场景优化
  - `base` - 原始基础模型，没有额外微调
- **量化标记**：
  - `q4_0`、`q4_1` - 4 位量化，占用内存较少，速度较快
  - `q5_0`、`q5_1` - 5 位量化，平衡性能和质量
  - `q8_0` - 8 位量化，质量较高，但需要更多内存
  - `f16` - 半精度浮点，质量最高，但内存占用最大

## 从模型库复制命令

使用 Ollama 模型库可以简化模型下载过程：

1. 点击界面上的"访问模型库"链接打开 [Ollama 官方模型库](https://ollama.ai/library)
2. 浏览并找到您感兴趣的模型
3. 复制模型页面上的命令，例如 `ollama run mistral`
4. 将命令粘贴到硅信的模型下载输入框中
5. 系统会自动识别并提取模型名称
6. 点击"下载"按钮开始下载或将其添加到下载队列

这种方式让您无需记忆模型名称和标签，直接使用官方推荐的配置。

## 模型文件存储位置

模型文件默认存储在以下位置：

**Windows**：

```
%USERPROFILE%\.ollama\models
```

**macOS**：

```
~/.ollama/models
```

**Linux**：

```
~/.ollama/models
```

您可以通过设置 `OLLAMA_MODELS` 环境变量更改存储位置：

```
OLLAMA_MODELS=D:\custom_path\models
```

## 下一步

成功下载模型后，您可以：

1. [管理模型](/ollama/manage) - 学习如何管理已安装的模型
2. [性能优化](/ollama/performance) - 优化模型性能以获得更好的体验
